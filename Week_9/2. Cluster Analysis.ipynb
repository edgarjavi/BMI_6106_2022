{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $2.$ Cluster Analysis\n",
    "\n",
    "Book: Practical Guide to Cluster Analysis in R: Unsupervised Machine Learning (Multivariate Analysis)\n",
    "\n",
    "### K-means Cluster Analysis \n",
    "\n",
    "K-means is another unsupervised learning algorithm whose main goal is to partition the data in non-overlapping clusters of elements from the data.\n",
    "\n",
    "The k-means algorithm can be itemized as:\n",
    "\n",
    "1. Determine the number of clusters (this can be a random guess)\n",
    "2. Construct distance matrix by randoming locating k number of points as the cluster center \n",
    "3. add observations to closest centroid based on some measurement of similarity (or dissimilarity)\n",
    "4. For each of the k clusters update the cluster centroid by calculating the new mean values of all the data points in the cluster. The centroid of a Kth cluster is a vector of length p containing the means of all variables for the observations in the kth cluster; p is the number of variables.\n",
    "5. Iteratively minimize the total within sum of square. That is, iterate steps 3 and 4 until the cluster assignments stop changing or the maximum number of iterations is reached. By default, the R software uses 10 as the default value for the maximum number of iterations.\n",
    "6. Based on the intrinsic properties of each k of clusters, investigate the best k for the model.\n",
    "\n",
    "In order to better understand this algorithm we will use a recurrent example from the UC Business Analytics R Programming Guide [http://uc-r.github.io/kmeans_clustering](http://uc-r.github.io/kmeans_clustering). On the USAarrests dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)  # data manipulation\n",
    "library(cluster)    # clustering algorithms\n",
    "library(factoextra) \n",
    "\n",
    "df <- USArrests\n",
    "df <- na.omit(df) ##remove any missing values\n",
    "df <- scale(df)\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance measurements:\n",
    "\n",
    "It is important to understand that there are many distance measurements that give weight to different properties of each group of points. The most commonly use is the euclidean distance which is derived from the geometric calculation of distances of two points on a plane:\n",
    "\n",
    "$ d_{ecu}(x,y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}$\n",
    "\n",
    "Some other examples of distance measurements are: manhattan, canberra, pearson correlation distance (widely used in gene expression analysis), spearman correlation (computes correlation between the rank of x and the ran of y variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets compute the matrix distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance <- get_dist(df)\n",
    "fviz_dist(distance, gradient = list(low = \"#00AFBB\", mid = \"white\", high = \"#FC4E07\")) ##Red more dissimilar \n",
    "#- blue more similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start computing the k-means by starting splitting the data in 2 clusters. the nstart argument attempts on multiple configurations and extracts the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2 <- kmeans(df, centers = 2, nstart = 25)\n",
    "str(k2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of kmeans is a list of arguments. The most important being:\n",
    "\n",
    "-  cluster: A vector of integers (from 1:k) indicating the cluster to which each point is allocated.\n",
    "-  centers: A matrix of cluster centers.\n",
    "-  totss: The total sum of squares.\n",
    "-  withinss: Vector of within-cluster sum of squares, one component per cluster.\n",
    "-  tot.withinss: Total within-cluster sum of squares, i.e. sum(withinss).\n",
    "-  betweenss: The between-cluster sum of squares, i.e. $totss-tot.withinss$.\n",
    "-  size: The number of points in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can spatially represent the clustering arrangement of the data by producing a PCA plot with the two main components and extrapollating the data onto this two-dimensional space. The function fviz_cluster produces this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fviz_cluster(k2, data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antother alternative is to produce simple scatterplots for each pair of variables (the highest correlated - the highest uncorrelated??) and compare with the PCA plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df %>%\n",
    "  as_tibble() %>%\n",
    "  mutate(cluster = k2$cluster,\n",
    "         state = row.names(USArrests)) %>%\n",
    "  ggplot(aes(UrbanPop, Murder, color = factor(cluster), label = state)) +\n",
    "  geom_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we know how many clusters should we select to get the best overall clustering?\n",
    "\n",
    "There are many methods that permit evaluate the optimal number of clusters. In here we will explain only one method the Elbow Methods, but the website given previously includes two more methods (Silhouette and Gap statistic)\n",
    "\n",
    "Elbow Method:\n",
    "\n",
    "Remember that the main goal of clustering is to minimize the within-cluster variation. The total within-cluster sum of square (similar to an ANOVA or a regression), measures how much variance there is in the clusters.\n",
    "\n",
    "The algorithm for the Elbow method basically calculates the wss for multiple $k$ values (e.g. 1 to 10 clusters), and plot the curve of wss vs the number of clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "\n",
    "# function to compute total within-cluster sum of square \n",
    "wss <- function(k) {\n",
    "  kmeans(df, k, nstart = 10 )$tot.withinss\n",
    "}\n",
    "\n",
    "# Compute and plot wss for k = 1 to k = 15\n",
    "k.values <- 1:15\n",
    "\n",
    "# extract wss for 2-15 clusters\n",
    "wss_values <- map_dbl(k.values, wss)\n",
    "\n",
    "plot(k.values, wss_values,\n",
    "       type=\"b\", pch = 19, frame = FALSE, \n",
    "       xlab=\"Number of clusters K\",\n",
    "       ylab=\"Total within-clusters sum of squares\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(123)\n",
    "\n",
    "fviz_nbclust(df, kmeans, method = \"wss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute k-means clustering with k = 4\n",
    "set.seed(123)\n",
    "final <- kmeans(df, 4, nstart = 25)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fviz_cluster(final, data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
